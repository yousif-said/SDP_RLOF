/home/rpl20001/anaconda3/envs/rlof/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/rpl20001/anaconda3/envs/rlof/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/500 [00:00<?, ?it/s]




























































 99%|█████████▉| 496/500 [00:31<00:00, 15.30it/s]
Epoch 0 complete.
Reward model training complete and saved at ./reward_model

100%|██████████| 500/500 [00:31<00:00, 15.75it/s]
